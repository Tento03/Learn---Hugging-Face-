{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-fRjl-SqEb8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='t5-base'\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
        "model=AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE7NM0sNqGvP",
        "outputId": "9b1ce755-0870-4da4-dc6a-328ca586ea2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def question_answer(dict_pairs):\n",
        "  answers=[]\n",
        "\n",
        "  for pair in dict_pairs:\n",
        "    question=pair['question']\n",
        "    context=pair['context']\n",
        "    input_text=f\"Qustion: {question} context : {context}\"\n",
        "    input_ids=tokenizer(input_text,return_tensors='pt')\n",
        "    input_ids=input_ids['input_ids']\n",
        "\n",
        "    #generate\n",
        "    output=model.generate(input_ids,max_length=100,num_beams=5,early_stopping=True,no_repeat_ngram_size=2)\n",
        "\n",
        "    #display\n",
        "    answer=tokenizer.decode(output[0],skip_special_tokens=True)\n",
        "    answers.append(answer)\n",
        "  return answers\n"
      ],
      "metadata": {
        "id": "uLOmHoQV6ooC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pairs = [\n",
        "    {\"question\": \"Who created GPT-2?\", \"context\": \"GPT-2 is a large language model created by OpenAI.\"},\n",
        "    {\"question\": \"What is GPT-2?\", \"context\": \"GPT-2 is a model that generates text based on input prompts.\"},\n",
        "    {\"question\": \"When was GPT-2 released?\", \"context\": \"GPT-2 was released by OpenAI in February 2019.\"}\n",
        "]\n"
      ],
      "metadata": {
        "id": "5-8b4THi7l4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers=question_answer(dict_pairs)"
      ],
      "metadata": {
        "id": "RBjDRIZT7oRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pair,answer in zip(dict_pairs,answers):\n",
        "  print(f\"Question: {pair['question']}\")\n",
        "  print(f\"context: {pair['context']}\")\n",
        "  print(f\"answer:{answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEtRkHVE7qsy",
        "outputId": "81b6562d-9acc-4fc0-e6e1-a47b186f35bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who created GPT-2?\n",
            "context: GPT-2 is a large language model created by OpenAI.\n",
            "answer:OpenAI\n",
            "Question: What is GPT-2?\n",
            "context: GPT-2 is a model that generates text based on input prompts.\n",
            "answer:model that generates text based on input prompts\n",
            "Question: When was GPT-2 released?\n",
            "context: GPT-2 was released by OpenAI in February 2019.\n",
            "answer:February 2019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJRZOhNi8FQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}